{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a9451c",
   "metadata": {},
   "source": [
    "Copyright by Arjun Sarkar Research Group Applied Systems Biology - Head: Prof. Dr. Marc Thilo Figge https://www.leibniz-hki.de/en/applied-systems-biology.html HKI-Center for Systems Biology of Infection Leibniz Institute for Natural Product Research and Infection Biology - Hans Knöll Insitute (HKI) Adolf-Reichwein-Straße 23, 07745 Jena, Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90bc886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af074e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c415bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2048\n",
    "MAX_SEQ_LENGTH = 40\n",
    "IMG_SIZE = 456\n",
    "\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20b08f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Num</th>\n",
       "      <th>infection</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ca</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cg</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mock</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ca</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cg</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video_Num infection  Patient  Patient_id\n",
       "0          1        ca        1    20180220\n",
       "1          2        cg        1    20180220\n",
       "2          3      mock        1    20180220\n",
       "3          4        ca        2    20180315\n",
       "4          5        cg        2    20180315"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Labels.csv')\n",
    "df = df.rename(columns={'Inefction_type':'infection'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a66ee005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Num</th>\n",
       "      <th>infection</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>ca</td>\n",
       "      <td>12</td>\n",
       "      <td>20181011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>34</td>\n",
       "      <td>cg</td>\n",
       "      <td>12</td>\n",
       "      <td>20181011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>35</td>\n",
       "      <td>mock</td>\n",
       "      <td>12</td>\n",
       "      <td>20181011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Video_Num infection  Patient  Patient_id\n",
       "24         33        ca       12    20181011\n",
       "25         34        cg       12    20181011\n",
       "26         35      mock       12    20181011"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[(df['Patient']==12)]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e2a3e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Num</th>\n",
       "      <th>infection</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ca</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cg</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mock</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ca</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cg</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>mock</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>ca</td>\n",
       "      <td>5</td>\n",
       "      <td>20180409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>cg</td>\n",
       "      <td>5</td>\n",
       "      <td>20180409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>mock</td>\n",
       "      <td>5</td>\n",
       "      <td>20180409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>ca</td>\n",
       "      <td>7</td>\n",
       "      <td>20180914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>cg</td>\n",
       "      <td>7</td>\n",
       "      <td>20180914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>mock</td>\n",
       "      <td>7</td>\n",
       "      <td>20180914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>ca</td>\n",
       "      <td>8</td>\n",
       "      <td>20180918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>cg</td>\n",
       "      <td>8</td>\n",
       "      <td>20180918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>mock</td>\n",
       "      <td>8</td>\n",
       "      <td>20180918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>ca</td>\n",
       "      <td>9</td>\n",
       "      <td>20180920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>cg</td>\n",
       "      <td>9</td>\n",
       "      <td>20180920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>mock</td>\n",
       "      <td>9</td>\n",
       "      <td>20180920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27</td>\n",
       "      <td>ca</td>\n",
       "      <td>10</td>\n",
       "      <td>20180925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>cg</td>\n",
       "      <td>10</td>\n",
       "      <td>20180925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29</td>\n",
       "      <td>mock</td>\n",
       "      <td>10</td>\n",
       "      <td>20180925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30</td>\n",
       "      <td>ca</td>\n",
       "      <td>11</td>\n",
       "      <td>20181009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31</td>\n",
       "      <td>cg</td>\n",
       "      <td>11</td>\n",
       "      <td>20181009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>mock</td>\n",
       "      <td>11</td>\n",
       "      <td>20181009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Video_Num infection  Patient  Patient_id\n",
       "0           1        ca        1    20180220\n",
       "1           2        cg        1    20180220\n",
       "2           3      mock        1    20180220\n",
       "3           4        ca        2    20180315\n",
       "4           5        cg        2    20180315\n",
       "5           6      mock        2    20180315\n",
       "6          13        ca        5    20180409\n",
       "7          14        cg        5    20180409\n",
       "8          15      mock        5    20180409\n",
       "9          18        ca        7    20180914\n",
       "10         19        cg        7    20180914\n",
       "11         20      mock        7    20180914\n",
       "12         21        ca        8    20180918\n",
       "13         22        cg        8    20180918\n",
       "14         23      mock        8    20180918\n",
       "15         24        ca        9    20180920\n",
       "16         25        cg        9    20180920\n",
       "17         26      mock        9    20180920\n",
       "18         27        ca       10    20180925\n",
       "19         28        cg       10    20180925\n",
       "20         29      mock       10    20180925\n",
       "21         30        ca       11    20181009\n",
       "22         31        cg       11    20181009\n",
       "23         32      mock       11    20181009"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([df, test]).drop_duplicates(keep=False)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69b39abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_arrays(df):\n",
    "\n",
    "    full_features = []\n",
    "    full_labels = []\n",
    "\n",
    "    for i,item in df.iterrows():\n",
    "    \n",
    "        features = np.load(f'/asbdata/Arjun/Bloodi/Patch_videos_numpy/videos/{item[0]}_features.npy')\n",
    "        labels = np.load(f'/asbdata/Arjun/Bloodi/Patch_videos_numpy/labels/{item[0]}_labels.npy')\n",
    "    \n",
    "        full_features.extend(features)\n",
    "        full_labels.extend(labels)\n",
    "    \n",
    "    final_features = np.array(full_features)\n",
    "    final_labels = np.array(full_labels)\n",
    "    \n",
    "    return final_features,final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "239ffae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 40, 2048)\n",
      "(1152, 1)\n",
      "(144, 40, 2048)\n",
      "(144, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = concat_arrays(train)\n",
    "test_data, test_labels = concat_arrays(test)\n",
    "\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b447a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    \n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'output_dim': self.output_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "235105f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'dense_dim': self.dense_dim,\n",
    "            'num_heads': self.num_heads\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "651b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "\n",
    "    def get_compiled_model():\n",
    "        \n",
    "        sequence_length = MAX_SEQ_LENGTH\n",
    "        embed_dim = NUM_FEATURES\n",
    "        dense_dim = 4\n",
    "        num_heads = 4\n",
    "        classes = 3\n",
    "\n",
    "        inputs = keras.Input(shape=(None, None))\n",
    "        x = PositionalEmbedding(sequence_length, embed_dim, name=\"frame_position_embedding\")(inputs)\n",
    "        x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b225427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    def run_experiment():\n",
    "        \n",
    "        filepath = \"Transformer_9.h5\"\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_best_only=True, verbose=1)\n",
    "        stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=10,verbose=1,mode='auto')\n",
    "\n",
    "        model = get_compiled_model()\n",
    "        history = model.fit(\n",
    "            train_data,\n",
    "            train_labels,\n",
    "            validation_split=0.1,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[checkpoint,stopping,reduce_lr],\n",
    "        )\n",
    "\n",
    "        model.load_weights(filepath)\n",
    "        _, accuracy = model.evaluate(test_data, test_labels)\n",
    "        print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4b7cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, None)]      0         \n",
      "                                                                 \n",
      " frame_position_embedding (P  (None, None, 2048)       81920     \n",
      " ositionalEmbedding)                                             \n",
      "                                                                 \n",
      " transformer_layer (Transfor  (None, None, 2048)       67162116  \n",
      " merEncoder)                                                     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 2048)             0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 6147      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,250,183\n",
      "Trainable params: 67,250,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asarkar/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.5089 - accuracy: 0.6182\n",
      "Epoch 1: val_loss improved from inf to 0.35015, saving model to Transformer_9.h5\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 1.5007 - accuracy: 0.6178 - val_loss: 0.3502 - val_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.8594\n",
      "Epoch 2: val_loss improved from 0.35015 to 0.25669, saving model to Transformer_9.h5\n",
      "33/33 [==============================] - 11s 333ms/step - loss: 0.4009 - accuracy: 0.8591 - val_loss: 0.2567 - val_accuracy: 0.8534 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9268\n",
      "Epoch 3: val_loss improved from 0.25669 to 0.20474, saving model to Transformer_9.h5\n",
      "33/33 [==============================] - 11s 331ms/step - loss: 0.1960 - accuracy: 0.9247 - val_loss: 0.2047 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.2529 - accuracy: 0.9111\n",
      "Epoch 4: val_loss did not improve from 0.20474\n",
      "33/33 [==============================] - 2s 60ms/step - loss: 0.2503 - accuracy: 0.9122 - val_loss: 0.4281 - val_accuracy: 0.8621 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9619\n",
      "Epoch 5: val_loss did not improve from 0.20474\n",
      "33/33 [==============================] - 2s 60ms/step - loss: 0.0990 - accuracy: 0.9614 - val_loss: 0.3140 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9863\n",
      "Epoch 6: val_loss did not improve from 0.20474\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 0.0447 - accuracy: 0.9865 - val_loss: 0.4571 - val_accuracy: 0.8793 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9795\n",
      "Epoch 7: val_loss did not improve from 0.20474\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 0.0582 - accuracy: 0.9797 - val_loss: 0.4273 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 8/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9844\n",
      "Epoch 8: val_loss did not improve from 0.20474\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 0.0378 - accuracy: 0.9836 - val_loss: 0.3851 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 9/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9902\n",
      "Epoch 9: val_loss improved from 0.20474 to 0.16507, saving model to Transformer_9.h5\n",
      "33/33 [==============================] - 11s 336ms/step - loss: 0.0273 - accuracy: 0.9894 - val_loss: 0.1651 - val_accuracy: 0.9483 - lr: 1.0000e-04\n",
      "Epoch 10/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9746\n",
      "Epoch 10: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 62ms/step - loss: 0.0794 - accuracy: 0.9749 - val_loss: 0.2259 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 11/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9756\n",
      "Epoch 11: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 61ms/step - loss: 0.0822 - accuracy: 0.9759 - val_loss: 0.2618 - val_accuracy: 0.9397 - lr: 1.0000e-04\n",
      "Epoch 12/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9980\n",
      "Epoch 12: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.4839 - val_accuracy: 0.9138 - lr: 1.0000e-04\n",
      "Epoch 13/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9932\n",
      "Epoch 13: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 0.0133 - accuracy: 0.9932 - val_loss: 0.9591 - val_accuracy: 0.8621 - lr: 1.0000e-04\n",
      "Epoch 14/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9980\n",
      "Epoch 14: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.7525 - val_accuracy: 0.8793 - lr: 1.0000e-04\n",
      "Epoch 15/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 15: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.7384 - val_accuracy: 0.8793 - lr: 1.0000e-04\n",
      "Epoch 16/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9483 - lr: 1.0000e-04\n",
      "Epoch 17/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9990    \n",
      "Epoch 17: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.7751 - val_accuracy: 0.8793 - lr: 1.0000e-04\n",
      "Epoch 18/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9990\n",
      "Epoch 18: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 1.1801 - val_accuracy: 0.8534 - lr: 1.0000e-04\n",
      "Epoch 19/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 6.5634e-04 - accuracy: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.16507\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 6.4878e-04 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 20/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.6770e-04 - accuracy: 1.0000\n",
      "Epoch 20: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 2.6474e-04 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 21/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.1466e-04 - accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 53ms/step - loss: 2.1532e-04 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 22/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.5739e-04 - accuracy: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 53ms/step - loss: 2.5580e-04 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 23/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.8031e-04 - accuracy: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 1.9142e-04 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 24/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.2139e-04 - accuracy: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 57ms/step - loss: 2.2439e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 25/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 3.1630e-04 - accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 3.1268e-04 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 26/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.3830e-04 - accuracy: 1.0000\n",
      "Epoch 26: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 2.3780e-04 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 27/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9990\n",
      "Epoch 27: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.4902 - val_accuracy: 0.9138 - lr: 1.0000e-05\n",
      "Epoch 28/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 4.8932e-04 - accuracy: 1.0000\n",
      "Epoch 28: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 57ms/step - loss: 4.8374e-04 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.9138 - lr: 1.0000e-05\n",
      "Epoch 29/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.9344e-04 - accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.16507\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 1.9177e-04 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.9052 - lr: 1.0000e-05\n",
      "Epoch 30/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 5.6310e-04 - accuracy: 1.0000\n",
      "Epoch 30: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 5.5729e-04 - accuracy: 1.0000 - val_loss: 0.6376 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 31/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.7461e-04 - accuracy: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 1.7263e-04 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 32/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 5.5937e-04 - accuracy: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 57ms/step - loss: 5.5328e-04 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 33/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.3996e-04 - accuracy: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 2.3724e-04 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 34/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.9996e-04 - accuracy: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 3.0362e-04 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 35/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.7442e-04 - accuracy: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 57ms/step - loss: 1.7421e-04 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 36/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.5930e-04 - accuracy: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 2.8532e-04 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 37/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.1300e-04 - accuracy: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 2.1084e-04 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 38/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 7.0042e-05 - accuracy: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.16507\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 6.9243e-05 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 39/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.2512e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.16507\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 1.2439e-04 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.9052 - lr: 1.0000e-06\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7792 - accuracy: 0.8750\n",
      "Test accuracy: 87.5%\n"
     ]
    }
   ],
   "source": [
    "trained_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24349b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25d73495",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model('Transformer_9.h5',custom_objects={'PositionalEmbedding': PositionalEmbedding,\n",
    "                                                                     'TransformerEncoder':TransformerEncoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b138d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7fc1a85f0220>,\n",
       "  <matplotlib.axis.YTick at 0x7fc1a86a22e0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc1a8672100>],\n",
       " [Text(0, 0, 'ca'), Text(0, 1, 'cg'), Text(0, 2, 'mock')])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_vals = trained_model.predict(test_data).argmax(axis=1)\n",
    "\n",
    "labels = ['ca','cg','mock']\n",
    "\n",
    "matrix = confusion_matrix (test_labels,predicted_vals)\n",
    "plot_confusion_matrix(matrix, figsize=(4,4))\n",
    "plt.xticks(range(3),labels, fontsize=10)\n",
    "plt.yticks(range(3),labels, fontsize=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
