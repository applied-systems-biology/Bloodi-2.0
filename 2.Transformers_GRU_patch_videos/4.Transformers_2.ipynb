{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8ab7e5",
   "metadata": {},
   "source": [
    "Copyright by Arjun Sarkar Research Group Applied Systems Biology - Head: Prof. Dr. Marc Thilo Figge https://www.leibniz-hki.de/en/applied-systems-biology.html HKI-Center for Systems Biology of Infection Leibniz Institute for Natural Product Research and Infection Biology - Hans Knöll Insitute (HKI) Adolf-Reichwein-Straße 23, 07745 Jena, Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90bc886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af074e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c415bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2048\n",
    "MAX_SEQ_LENGTH = 40\n",
    "IMG_SIZE = 456\n",
    "\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b08f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Num</th>\n",
       "      <th>infection</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ca</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cg</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mock</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ca</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cg</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video_Num infection  Patient  Patient_id\n",
       "0          1        ca        1    20180220\n",
       "1          2        cg        1    20180220\n",
       "2          3      mock        1    20180220\n",
       "3          4        ca        2    20180315\n",
       "4          5        cg        2    20180315"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Labels.csv')\n",
    "df = df.rename(columns={'Inefction_type':'infection'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66ee005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Num</th>\n",
       "      <th>infection</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ca</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cg</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>mock</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video_Num infection  Patient  Patient_id\n",
       "3          4        ca        2    20180315\n",
       "4          5        cg        2    20180315\n",
       "5          6      mock        2    20180315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[(df['Patient']==2)]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2a3e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Num</th>\n",
       "      <th>infection</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ca</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cg</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mock</td>\n",
       "      <td>1</td>\n",
       "      <td>20180220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>ca</td>\n",
       "      <td>5</td>\n",
       "      <td>20180409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>cg</td>\n",
       "      <td>5</td>\n",
       "      <td>20180409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>mock</td>\n",
       "      <td>5</td>\n",
       "      <td>20180409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>ca</td>\n",
       "      <td>7</td>\n",
       "      <td>20180914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>cg</td>\n",
       "      <td>7</td>\n",
       "      <td>20180914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>mock</td>\n",
       "      <td>7</td>\n",
       "      <td>20180914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>ca</td>\n",
       "      <td>8</td>\n",
       "      <td>20180918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>cg</td>\n",
       "      <td>8</td>\n",
       "      <td>20180918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>mock</td>\n",
       "      <td>8</td>\n",
       "      <td>20180918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>ca</td>\n",
       "      <td>9</td>\n",
       "      <td>20180920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>cg</td>\n",
       "      <td>9</td>\n",
       "      <td>20180920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>mock</td>\n",
       "      <td>9</td>\n",
       "      <td>20180920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27</td>\n",
       "      <td>ca</td>\n",
       "      <td>10</td>\n",
       "      <td>20180925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>cg</td>\n",
       "      <td>10</td>\n",
       "      <td>20180925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29</td>\n",
       "      <td>mock</td>\n",
       "      <td>10</td>\n",
       "      <td>20180925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30</td>\n",
       "      <td>ca</td>\n",
       "      <td>11</td>\n",
       "      <td>20181009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31</td>\n",
       "      <td>cg</td>\n",
       "      <td>11</td>\n",
       "      <td>20181009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>mock</td>\n",
       "      <td>11</td>\n",
       "      <td>20181009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>ca</td>\n",
       "      <td>12</td>\n",
       "      <td>20181011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>34</td>\n",
       "      <td>cg</td>\n",
       "      <td>12</td>\n",
       "      <td>20181011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>35</td>\n",
       "      <td>mock</td>\n",
       "      <td>12</td>\n",
       "      <td>20181011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Video_Num infection  Patient  Patient_id\n",
       "0           1        ca        1    20180220\n",
       "1           2        cg        1    20180220\n",
       "2           3      mock        1    20180220\n",
       "6          13        ca        5    20180409\n",
       "7          14        cg        5    20180409\n",
       "8          15      mock        5    20180409\n",
       "9          18        ca        7    20180914\n",
       "10         19        cg        7    20180914\n",
       "11         20      mock        7    20180914\n",
       "12         21        ca        8    20180918\n",
       "13         22        cg        8    20180918\n",
       "14         23      mock        8    20180918\n",
       "15         24        ca        9    20180920\n",
       "16         25        cg        9    20180920\n",
       "17         26      mock        9    20180920\n",
       "18         27        ca       10    20180925\n",
       "19         28        cg       10    20180925\n",
       "20         29      mock       10    20180925\n",
       "21         30        ca       11    20181009\n",
       "22         31        cg       11    20181009\n",
       "23         32      mock       11    20181009\n",
       "24         33        ca       12    20181011\n",
       "25         34        cg       12    20181011\n",
       "26         35      mock       12    20181011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([df, test]).drop_duplicates(keep=False)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b39abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_arrays(df):\n",
    "\n",
    "    full_features = []\n",
    "    full_labels = []\n",
    "\n",
    "    for i,item in df.iterrows():\n",
    "    \n",
    "        features = np.load(f'/asbdata/Arjun/Bloodi/Patch_videos_numpy/videos/{item[0]}_features.npy')\n",
    "        labels = np.load(f'/asbdata/Arjun/Bloodi/Patch_videos_numpy/labels/{item[0]}_labels.npy')\n",
    "    \n",
    "        full_features.extend(features)\n",
    "        full_labels.extend(labels)\n",
    "    \n",
    "    final_features = np.array(full_features)\n",
    "    final_labels = np.array(full_labels)\n",
    "    \n",
    "    return final_features,final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239ffae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 40, 2048)\n",
      "(1152, 1)\n",
      "(144, 40, 2048)\n",
      "(144, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = concat_arrays(train)\n",
    "test_data, test_labels = concat_arrays(test)\n",
    "\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b447a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    \n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'output_dim': self.output_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "235105f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'dense_dim': self.dense_dim,\n",
    "            'num_heads': self.num_heads\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "651b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "\n",
    "    def get_compiled_model():\n",
    "        \n",
    "        sequence_length = MAX_SEQ_LENGTH\n",
    "        embed_dim = NUM_FEATURES\n",
    "        dense_dim = 4\n",
    "        num_heads = 4\n",
    "        classes = 3\n",
    "\n",
    "        inputs = keras.Input(shape=(None, None))\n",
    "        x = PositionalEmbedding(sequence_length, embed_dim, name=\"frame_position_embedding\")(inputs)\n",
    "        x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "        x = layers.GlobalMaxPooling1D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b225427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    def run_experiment():\n",
    "        \n",
    "        filepath = \"Transformer_2.h5\"\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_best_only=True, verbose=1)\n",
    "        stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=10,verbose=1,mode='auto')\n",
    "\n",
    "        model = get_compiled_model()\n",
    "        history = model.fit(\n",
    "            train_data,\n",
    "            train_labels,\n",
    "            validation_split=0.1,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[checkpoint,stopping,reduce_lr],\n",
    "        )\n",
    "\n",
    "        model.load_weights(filepath)\n",
    "        _, accuracy = model.evaluate(test_data, test_labels)\n",
    "        print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b7cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None)]      0         \n",
      "                                                                 \n",
      " frame_position_embedding (P  (None, None, 2048)       81920     \n",
      " ositionalEmbedding)                                             \n",
      "                                                                 \n",
      " transformer_layer (Transfor  (None, None, 2048)       67162116  \n",
      " merEncoder)                                                     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 2048)             0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 6147      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,250,183\n",
      "Trainable params: 67,250,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asarkar/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 1.3481 - accuracy: 0.6541\n",
      "Epoch 1: val_loss improved from inf to 0.18051, saving model to Transformer_2.h5\n",
      "33/33 [==============================] - 11s 271ms/step - loss: 1.2716 - accuracy: 0.6641 - val_loss: 0.1805 - val_accuracy: 0.9138 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.5553 - accuracy: 0.8114\n",
      "Epoch 2: val_loss did not improve from 0.18051\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.5450 - accuracy: 0.8127 - val_loss: 0.5009 - val_accuracy: 0.8534 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.3041 - accuracy: 0.8933\n",
      "Epoch 3: val_loss improved from 0.18051 to 0.04443, saving model to Transformer_2.h5\n",
      "33/33 [==============================] - 8s 265ms/step - loss: 0.2913 - accuracy: 0.8986 - val_loss: 0.0444 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.1414 - accuracy: 0.9472\n",
      "Epoch 4: val_loss did not improve from 0.04443\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.1528 - accuracy: 0.9421 - val_loss: 0.0624 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.0751 - accuracy: 0.9688\n",
      "Epoch 5: val_loss did not improve from 0.04443\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0757 - accuracy: 0.9691 - val_loss: 0.0668 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.0708 - accuracy: 0.9752\n",
      "Epoch 6: val_loss improved from 0.04443 to 0.02747, saving model to Transformer_2.h5\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0763 - accuracy: 0.9739 - val_loss: 0.0275 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.1267 - accuracy: 0.9504\n",
      "Epoch 7: val_loss did not improve from 0.02747\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.1245 - accuracy: 0.9517 - val_loss: 0.1340 - val_accuracy: 0.9397 - lr: 1.0000e-04\n",
      "Epoch 8/500\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 0.0251 - accuracy: 0.9940\n",
      "Epoch 8: val_loss did not improve from 0.02747\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.0344 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9942\n",
      "Epoch 9: val_loss did not improve from 0.02747\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.0324 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 10/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 10: val_loss improved from 0.02747 to 0.01814, saving model to Transformer_2.h5\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0181 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 11/500\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 0.0427 - accuracy: 0.9844\n",
      "Epoch 11: val_loss did not improve from 0.01814\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0408 - accuracy: 0.9846 - val_loss: 0.0255 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 12/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.0103 - accuracy: 0.9946\n",
      "Epoch 12: val_loss did not improve from 0.01814\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0097 - accuracy: 0.9952 - val_loss: 0.1261 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 13/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.0058 - accuracy: 0.9968\n",
      "Epoch 13: val_loss did not improve from 0.01814\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0054 - accuracy: 0.9971 - val_loss: 0.0329 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 14/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 0.0147 - accuracy: 0.9946\n",
      "Epoch 14: val_loss improved from 0.01814 to 0.01453, saving model to Transformer_2.h5\n",
      "33/33 [==============================] - 8s 262ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0145 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9942\n",
      "Epoch 15: val_loss improved from 0.01453 to 0.00893, saving model to Transformer_2.h5\n",
      "33/33 [==============================] - 8s 263ms/step - loss: 0.0110 - accuracy: 0.9942 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 16/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 17/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 7.8579e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 18/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 3.9930e-04 - accuracy: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 3.6484e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 19/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 4.7985e-04 - accuracy: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 4.7513e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 20/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 3.4678e-04 - accuracy: 1.0000\n",
      "Epoch 20: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 3.3080e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 2.7893e-04 - accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 2.7893e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 22/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 2.4130e-04 - accuracy: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 2.2510e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 23/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 1.6589e-04 - accuracy: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.00893\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 2.0944e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 3.7499e-04 - accuracy: 1.0000\n",
      "Epoch 24: val_loss improved from 0.00893 to 0.00806, saving model to Transformer_2.h5\n",
      "33/33 [==============================] - 8s 257ms/step - loss: 3.7499e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 25/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 2.7600e-04 - accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 2.4826e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 26/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 5.4286e-05 - accuracy: 1.0000\n",
      "Epoch 26: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 5.3854e-05 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 27/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.5548e-04 - accuracy: 1.0000\n",
      "Epoch 27: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 1.5371e-04 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 8.3047e-05 - accuracy: 1.0000\n",
      "Epoch 28: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 8.3765e-05 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 29/500\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 7.9039e-05 - accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 7.4271e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 30/500\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 5.4406e-05 - accuracy: 1.0000\n",
      "Epoch 30: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 5.1596e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 3.5209e-04 - accuracy: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 3.5209e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 32/500\n",
      "30/33 [==========================>...] - ETA: 0s - loss: 1.6794e-04 - accuracy: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 1.6419e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 1.2482e-04 - accuracy: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 1.2482e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 34/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 5.3135e-05 - accuracy: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.00806\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 4.9637e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 4.3798e-05 - accuracy: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 4.3798e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 36/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 6.6538e-05 - accuracy: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 6.6736e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 37/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 9.1963e-05 - accuracy: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 8.6888e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 38/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 4.5382e-05 - accuracy: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 4.3049e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 39/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 2.5816e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 2.3851e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - ETA: 0s - loss: 8.7954e-05 - accuracy: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 8.7954e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 41/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 4.1331e-05 - accuracy: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 4.6822e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 42/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 2.7415e-05 - accuracy: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 1.2860e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 43/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 5.2319e-05 - accuracy: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 5.1730e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 44/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 2.1335e-05 - accuracy: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.00806\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 2.4708e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 45/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 2.8804e-05 - accuracy: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 2.7535e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 46/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 3.2489e-05 - accuracy: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 3.0738e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 47/500\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 3.5466e-05 - accuracy: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 3.4116e-05 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 48/500\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 5.2557e-05 - accuracy: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 5.3944e-05 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 49/500\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 4.6567e-05 - accuracy: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 4.6342e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 50/500\n",
      "29/33 [=========================>....] - ETA: 0s - loss: 3.1948e-05 - accuracy: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 5.6068e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 51/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 1.0926e-04 - accuracy: 1.0000\n",
      "Epoch 51: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 1.0824e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 52/500\n",
      "32/33 [============================>.] - ETA: 0s - loss: 2.9661e-05 - accuracy: 1.0000\n",
      "Epoch 52: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 3.0106e-05 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 53/500\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 1.6255e-05 - accuracy: 1.0000\n",
      "Epoch 53: val_loss did not improve from 0.00806\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 1.5911e-05 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 54/500\n",
      "31/33 [===========================>..] - ETA: 0s - loss: 2.2615e-04 - accuracy: 1.0000\n",
      "Epoch 54: val_loss did not improve from 0.00806\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 2.1723e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9914 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0826 - accuracy: 0.7014\n",
      "Test accuracy: 70.14%\n"
     ]
    }
   ],
   "source": [
    "trained_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24349b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d73495",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model('Transformer_2.h5',custom_objects={'PositionalEmbedding': PositionalEmbedding,\n",
    "                                                                     'TransformerEncoder':TransformerEncoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b138d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f75546d14c0>,\n",
       "  <matplotlib.axis.YTick at 0x7f75546d8e20>,\n",
       "  <matplotlib.axis.YTick at 0x7f7554674ac0>],\n",
       " [Text(0, 0, 'ca'), Text(0, 1, 'cg'), Text(0, 2, 'mock')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_vals = trained_model.predict(test_data).argmax(axis=1)\n",
    "\n",
    "labels = ['ca','cg','mock']\n",
    "\n",
    "matrix = confusion_matrix (test_labels,predicted_vals)\n",
    "plot_confusion_matrix(matrix, figsize=(4,4))\n",
    "plt.xticks(range(3),labels, fontsize=10)\n",
    "plt.yticks(range(3),labels, fontsize=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
